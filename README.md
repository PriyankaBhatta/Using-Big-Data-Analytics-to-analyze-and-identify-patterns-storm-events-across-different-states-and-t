# Using Big Data Analytics to analyze and identify patterns storm events across different states and territories of USA for year 2022

PySpark, a strong distributed computing framework for big data processing, was used throughout the project. On large data sets, PySpark helps effective data transformation, modeling, and manipulation.

The dataset used in this study was collected from NOAA, the United States government's authoritative source for environmental information. The dataset contains statistics on storm events that happened in the United States in 2022. For data cleaning, preprocessing, analysis, modeling, and visualization, PySpark libraries were used.

The PySpark libraries provided the capabilities required for data processing, transformation, and analysis. The dataset was imported into a PySpark DataFrame, which allowed for rapid distributed data processing. For data cleaning and preprocessing, PySpark's built-in functions and operations were used, ensuring that the dataset was in an acceptable format for future analysis.

PySpark's strong data manipulation capabilities were used throughout the exploratory research phase to extract insights and obtain a deeper knowledge of the storm events data. Several statistical analysis, aggregations, and transformations were done on the dataset to reveal patterns, trends, and descriptive statistics.

PySpark's machine learning package was used to model the data and discover clusters within storm occurrences. The KMeans and BisectingKMeans clustering techniques were used specifically. These algorithms allowed the storm occurrences to be divided into various groups based on similarities in their attributes.

The Silhouette score, a generally used metric for assessing the quality of clustering findings, was used to evaluate the model. The silhouette score assesses the compactness and separation of clusters, indicating the success of the clustering process.

In summary, this study shows how to use PySpark to analyze storm occurrences from start to finish, from data loading and preprocessing through modeling and visualization. The PySpark framework, with its extensive libraries and features, offers a stable and scalable platform for conducting the analysis, finding patterns in the data, and gaining significant insights for further research and decision-making.


Link for datasets: https://www.ncei.noaa.gov/pub/data/swdi/stormevents/csvfiles/
